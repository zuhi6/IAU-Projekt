{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import randint\n",
    "import math\n",
    "from datetime import date\n",
    "import datetime\n",
    "from functools import reduce\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data = pd.read_csv('./data/personal_train.csv')\n",
    "personal_data = personal_data.drop(['Unnamed: 0'], axis=1)\n",
    "other_data = pd.read_csv('./data/other_train.csv')\n",
    "other_data = other_data.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "merged = pd.merge(personal_data,other_data,on=[\"name\",\"address\"])\n",
    "duplicated = merged.duplicated(subset=[\"name\",\"address\"],keep=False)\n",
    "duplicates = pd.DataFrame(columns=merged.columns)\n",
    "indexes_to_drop = []\n",
    "merged_without_duplicates = pd.DataFrame(columns=merged.columns)\n",
    "for index, row in merged.iterrows():\n",
    "    if(duplicated[index]):\n",
    "        duplicates = duplicates.append(merged.iloc[index],ignore_index=True)\n",
    "        indexes_to_drop.append(index)\n",
    "\n",
    "duplicates.sort_values([\"name\",\"address\"])\n",
    "\n",
    "\n",
    "\n",
    "merged_without_duplicates = merged\n",
    "\n",
    "for index in indexes_to_drop:\n",
    "    merged_without_duplicates = merged_without_duplicates.drop(merged.index[index])\n",
    "\n",
    "merged = merged_without_duplicates\n",
    "\n",
    "def checkNaN(arr):\n",
    "    for item in arr:\n",
    "        if((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def checkQuestionMark(arr):\n",
    "    for item in arr:\n",
    "        if(item is not '?'):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def nanOrQuestionMark(arr):\n",
    "    for item in arr:\n",
    "        if(item is not '?' and ((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item))):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def filter_nan_question_mark(arr):\n",
    "    result = []\n",
    "    for item in arr:\n",
    "        if(item is not '?' and ((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item))):\n",
    "            result.append(item)\n",
    "    return result        \n",
    "\n",
    "def getUniqueRow(startIndex,endIndex):\n",
    "    row_dict = {}\n",
    "\n",
    "    for column in duplicates.columns: \n",
    "        temp = []\n",
    "        for index in range(startIndex,endIndex):\n",
    "            temp.append(duplicates.iloc[index][column])\n",
    "         \n",
    "        if(checkNaN(temp)):\n",
    "            row_dict[column] = np.nan\n",
    "        elif(checkQuestionMark(temp)):\n",
    "            row_dict[column] = '?'\n",
    "        elif(nanOrQuestionMark(temp)):\n",
    "            row_dict[column] = '?'\n",
    "        else:\n",
    "            temp = filter_nan_question_mark(temp)\n",
    "            value = randint(0,len(temp)-1)\n",
    "            row_dict[column] = temp[value]\n",
    "    return row_dict\n",
    "    \n",
    "count = 0\n",
    "lastDuplicate = duplicates.iloc[0][\"name\"]\n",
    "columns = duplicates.columns.values\n",
    "for index,row in duplicates.iterrows():\n",
    "    entry = duplicates.iloc[index]\n",
    "    name = entry[\"name\"]\n",
    "    if(name == lastDuplicate):\n",
    "        count += 1\n",
    "    else:\n",
    "        merged = merged.append(getUniqueRow(index-count,index),ignore_index=True)\n",
    "        lastDuplicate = name\n",
    "        count = 1\n",
    "        \n",
    "    if(len(duplicates) - 1 == index):\n",
    "        merged = merged.append(getUniqueRow(index-count+1,index + 1),ignore_index=True)\n",
    "        \n",
    "        \n",
    "for index, row in merged.iterrows():\n",
    "    newRow = eval(row[\"medical_info\"])\n",
    "    for key, value in newRow.items():\n",
    "        merged.loc[index,key] = value\n",
    "\n",
    "merged = merged.drop(\"medical_info\",axis=1)\n",
    "\n",
    "for column in merged.columns:\n",
    "    merged[column] = merged[column].map(lambda x: np.nan if '?' in str(x) or 'nan' == str(x) else x)\n",
    "\n",
    "averageAge = np.nanmean(merged[\"age\"].tolist())\n",
    "\n",
    "newDate = datetime.datetime(math.floor(datetime.datetime.now().year - averageAge), datetime.datetime.now().month, datetime.datetime.now().day,\n",
    "                           datetime.datetime.now().hour, datetime.datetime.now().minute).date()\n",
    "\n",
    "def format_date(string):\n",
    "    for fmt in [\"%Y/%m/%d\", \"%Y%m%d\", \"%y-%m-%d\", \"%Y-%m-%d\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d %H %M %S\", \"%d/%m/%Y\"]:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(string, fmt).date()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    raise ValueError(string)\n",
    "\n",
    "# Funkcia vráti všetky unikátne hodnoty stĺpca\n",
    "def getUniqueValues(arr):\n",
    "    return arr.value_counts(normalize=True, dropna=True).index\n",
    "\n",
    "# Funkcia vráti pomery unikátnych hodnôt stĺpca\n",
    "def getRatio(arr):\n",
    "    return arr.value_counts(normalize=True, dropna=True).values\n",
    "\n",
    "# Nahradí NaN za jednu z hodnôt stĺpca tak, aby pomer hodnôt zostal zachovaný\n",
    "def fillNanAccordingToRatio(arr):\n",
    "    return arr.fillna(pd.Series(np.random.choice(getUniqueValues(arr), p=getRatio(arr), size=len(arr))))\n",
    "\n",
    "#naformatuje datum\n",
    "merged[\"date_of_birth\"] = merged[\"date_of_birth\"].map(lambda x: format_date(x) if type(x) is str else x)\n",
    "#doplni chybajuce veky s priemerom\n",
    "merged[\"age\"] = merged[\"age\"].map(lambda x: math.floor(averageAge) if str(x) == 'nan' or x > 109 else x)\n",
    "#doplni chybajuce datumy na zaklade priemerneho veku\n",
    "merged[\"date_of_birth\"] = merged[\"date_of_birth\"].map(lambda x: newDate if str(x) == 'nan' else x)\n",
    "#opravi datumy ktore su vacsie ako aktualne na zaklade veku\n",
    "\n",
    "#opravi datumy ktore su vacsie ako aktualne na zaklade veku\n",
    "i = 0\n",
    "for date in merged[\"date_of_birth\"]:\n",
    "    if(date > datetime.datetime.now().date()):\n",
    "        modifiedDate = datetime.datetime(datetime.datetime.now().year-int(merged[\"age\"][i]), date.month, date.day).date()\n",
    "        merged[\"date_of_birth\"][i] = modifiedDate \n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "    #doplni chybajuce TT4 pomocou algoritmu k najblizsich\n",
    "k = 5\n",
    "kNearest = []\n",
    "\n",
    "i = 0\n",
    "for tt4 in merged[\"TT4\"]:\n",
    "    if(str(tt4) == 'nan'):\n",
    "        kNearest = []\n",
    "        for index in range(2*k+1):\n",
    "            if(i+k-index < len(merged) and i+k-index > -1 and i+k-index != i and str(merged[\"TT4\"][i+k-index]) != 'nan' and merged[\"T4U\"][i+k-index] != '?'):\n",
    "                kNearest.append(merged[\"TT4\"][i+k-index])\n",
    "        nearestAvg = reduce(lambda x, y: x + y, kNearest) / len(kNearest)\n",
    "        merged[\"TT4\"][i] = math.floor(nearestAvg)\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "#doplni chybajuce T4U pomocou algoritmu k najblizsich\n",
    "k = 5\n",
    "kNearest = []\n",
    "\n",
    "i = 0\n",
    "for tt4 in merged[\"T4U\"]:\n",
    "    if(str(tt4) == 'nan'):\n",
    "        kNearest = []\n",
    "        for index in range(2*k+1):\n",
    "            if(i+k-index < len(merged) and i+k-index > -1 and i+k-index != i and str(merged[\"T4U\"][i+k-index]) != 'nan' and merged[\"T4U\"][i+k-index] != '?'):\n",
    "                kNearest.append(merged[\"T4U\"][i+k-index])\n",
    "        nearestAvg = reduce(lambda x, y: x + y, kNearest) / len(kNearest)\n",
    "        merged[\"T4U\"][i] = nearestAvg\n",
    "    i += 1\n",
    "    \n",
    "#doplni chybajuce T4U pomocou algoritmu k najblizsich\n",
    "k = 5\n",
    "kNearest = []\n",
    "\n",
    "i = 0\n",
    "for tt4 in merged[\"TSH\"]:\n",
    "    if(str(tt4) == 'nan'):\n",
    "        kNearest = []\n",
    "        for index in range(2*k+1):\n",
    "            if(i+k-index < len(merged) and i+k-index > -1 and i+k-index != i and str(merged[\"TSH\"][i+k-index]) != 'nan' and merged[\"TSH\"][i+k-index] != '?'):\n",
    "                kNearest.append(merged[\"TSH\"][i+k-index])\n",
    "        nearestAvg = reduce(lambda x, y: x + y, kNearest) / len(kNearest)\n",
    "        merged[\"TSH\"][i] = nearestAvg\n",
    "    i += 1\n",
    "\n",
    "median = np.nanmedian(merged[\"T3\"].tolist())\n",
    "\n",
    "merged[\"T3\"] = merged[\"T3\"].map(lambda x: median if str(x) == 'nan' or x == '?' else x)\n",
    "\n",
    "median = np.nanmedian(merged[\"education-num\"].tolist())\n",
    "\n",
    "merged[\"education-num\"] = merged[\"education-num\"].map(lambda x: median if str(x) == 'nan' else x)\n",
    "def mapTrueFalse(x):\n",
    "    if(\"t\" in str(x).lower()):\n",
    "        return \"t\"\n",
    "    elif(\"f\" in str(x).lower()):\n",
    "        return \"f\"\n",
    "    else:\n",
    "        return np.nan\n",
    "true_false_columns = [\"sick\",\"T3 measured\",\"query hypothyroid\", \"query hyperthyroid\",\"FTI measured\",\"lithium\",\"TT4 measured\", \"pregnant\",\n",
    "                     \"thyroid surgery\",\"TSH measured\",\"query on thyroxine\",\"I131 treatment\",\"on thyroxine\",\"psych\", \"T4U measured\", \"tumor\",\n",
    "                     ]\n",
    "\n",
    "for column in true_false_columns:\n",
    "    merged[column] = merged[column].map(lambda x: mapTrueFalse(x))\n",
    "    \n",
    "average_columns = [\"age\",\"TT4\",\"T4U\",\"capital-loss\",\"TSH\",\"FTI\"]\n",
    "for column in average_columns:\n",
    "    merged[column] = merged[column].map(lambda x: float(x))\n",
    "    average = np.nanmean(merged[column].tolist())\n",
    "    merged[column] = merged[column].map(lambda x: math.floor(average) if 'nan' in str(x).lower() else x)\n",
    "    \n",
    "merged[\"sick\"] = fillNanAccordingToRatio(merged[\"sick\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "averageCapital = np.nanmean(merged[\"capital-loss\"].tolist())\n",
    "\n",
    "merged[\"sex\"] = fillNanAccordingToRatio(merged[\"sex\"])\n",
    "merged[\"workclass\"] = fillNanAccordingToRatio(merged[\"workclass\"])\n",
    "merged[\"native-country\"] = fillNanAccordingToRatio(merged[\"native-country\"])\n",
    "merged[\"occupation\"] = fillNanAccordingToRatio(merged[\"occupation\"])\n",
    "merged[\"T3 measured\"] = fillNanAccordingToRatio(merged[\"T3 measured\"])\n",
    "merged = merged.drop(\"TBG\",axis=1)\n",
    "merged = merged.drop(\"TBG measured\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2237 entries, 0 to 2236\n",
      "Data columns (total 43 columns):\n",
      "name                         2237 non-null object\n",
      "address                      2237 non-null object\n",
      "age                          2237 non-null float64\n",
      "sex                          2237 non-null object\n",
      "date_of_birth                2237 non-null object\n",
      "query hyperthyroid           2237 non-null object\n",
      "FTI measured                 2237 non-null object\n",
      "education                    2237 non-null object\n",
      "lithium                      2237 non-null object\n",
      "TT4                          2237 non-null float64\n",
      "T4U                          2237 non-null float64\n",
      "capital-loss                 2237 non-null float64\n",
      "capital-gain                 2237 non-null float64\n",
      "tumor                        2237 non-null object\n",
      "TSH                          2237 non-null float64\n",
      "T3                           2237 non-null float64\n",
      "fnlwgt                       2237 non-null float64\n",
      "hours-per-week               2237 non-null float64\n",
      "relationship                 2237 non-null object\n",
      "sick                         2237 non-null object\n",
      "workclass                    2237 non-null object\n",
      "TT4 measured                 2237 non-null object\n",
      "class                        2237 non-null object\n",
      "marital-status               2237 non-null object\n",
      "goitre                       2237 non-null object\n",
      "native-country               2237 non-null object\n",
      "hypopituitary                2237 non-null object\n",
      "on antithyroid medication    2237 non-null object\n",
      "referral source              2237 non-null object\n",
      "education-num                2237 non-null float64\n",
      "occupation                   2237 non-null object\n",
      "race                         2237 non-null object\n",
      "FTI                          2237 non-null float64\n",
      "query hypothyroid            2237 non-null object\n",
      "T4U measured                 2237 non-null object\n",
      "pregnant                     2237 non-null object\n",
      "thyroid surgery              2237 non-null object\n",
      "TSH measured                 2237 non-null object\n",
      "query on thyroxine           2237 non-null object\n",
      "I131 treatment               2237 non-null object\n",
      "on thyroxine                 2237 non-null object\n",
      "T3 measured                  2237 non-null object\n",
      "psych                        2237 non-null object\n",
      "dtypes: float64(11), object(32)\n",
      "memory usage: 751.6+ KB\n"
     ]
    }
   ],
   "source": [
    "merged.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
