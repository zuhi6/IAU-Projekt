{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import randint\n",
    "import math\n",
    "from datetime import date\n",
    "import datetime\n",
    "from functools import reduce\n",
    "import warnings\n",
    "import random\n",
    "import re\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data = pd.read_csv('./data/personal_train.csv')\n",
    "personal_data = personal_data.drop(['Unnamed: 0'],axis=1)\n",
    "other_data = pd.read_csv('./data/other_train.csv')\n",
    "other_data = other_data.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zlúčenie dvoch datasetov do jedného, na základe stĺpcov, alebo stĺpca (v parametroch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MergeTransformer(TransformerMixin):\n",
    "    def __init__(self,df1,df2,cols):\n",
    "        self.df1 = df1\n",
    "        self.df2 = df2\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        df = pd.merge(self.df1,self.df2,on=self.cols)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprv sa uložia všetky duplikáty z DF, v pôvodnom sa vymažú, a následne sa vytvorí 1 unikátny záznam z množiny duplikátov, ktorý sa uloží na pôvodný dataset. Ak má stĺpec: spojité hodnoty, tak sa vyráta priemer. Ak má diskrétne, tak sa priradí náhodne, ak má samé NaN alebo ?, tak NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeduplicationTransformer(TransformerMixin):\n",
    "    def __init__(self,cols,groupBy):\n",
    "        self.cols = cols\n",
    "        self.groupBy = groupBy\n",
    "    \n",
    "    def _checkNaN(self,arr):\n",
    "        for item in arr:\n",
    "            if((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item)):\n",
    "                return False\n",
    "        return True\n",
    "    def _checkQuestionMark(self,arr):\n",
    "        for item in arr:\n",
    "            if(item is not '?'):\n",
    "                return False\n",
    "        return True\n",
    "    def _nanOrQuestionMark(self,arr):\n",
    "        for item in arr:\n",
    "            if(item is not '?' and ((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item))):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _filter_nan_question_mark(self,arr):\n",
    "        result = []\n",
    "        for item in arr:\n",
    "            if(item is not '?' and ((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item))):\n",
    "                result.append(item)\n",
    "        return result \n",
    "    \n",
    "    def _getUniqueRow(self,duplicates,startIndex,endIndex):\n",
    "        row_dict = {}\n",
    "\n",
    "        for column in duplicates.columns: \n",
    "            temp = []\n",
    "            for index in range(startIndex,endIndex):\n",
    "                temp.append(duplicates.iloc[index][column])\n",
    "         \n",
    "            if(self._checkNaN(temp)):\n",
    "                row_dict[column] = np.nan\n",
    "            elif(self._checkQuestionMark(temp)):\n",
    "                row_dict[column] = np.nan\n",
    "            elif(self._nanOrQuestionMark(temp)):\n",
    "                row_dict[column] = np.nan\n",
    "            else:\n",
    "                temp = self._filter_nan_question_mark(temp)\n",
    "                if(np.array(temp).dtype == 'float64'):\n",
    "                    row_dict[column] = np.mean(temp)\n",
    "                else:\n",
    "                    value = randint(0,len(temp)-1)\n",
    "                    row_dict[column] = temp[value]\n",
    "        return row_dict\n",
    "\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        duplicated = df.duplicated(subset=self.cols,keep=False)\n",
    "        duplicates = pd.DataFrame(columns=df.columns)\n",
    "        indexes_to_drop = []\n",
    "        df_without_duplicates = pd.DataFrame(columns=df.columns)\n",
    "        for index, row in df.iterrows():\n",
    "            if(duplicated[index]):\n",
    "                duplicates = duplicates.append(df.iloc[index],ignore_index=True)\n",
    "                indexes_to_drop.append(index)\n",
    "\n",
    "        duplicates.sort_values(self.cols)\n",
    "        df_without_duplicates = df\n",
    "        for index in indexes_to_drop:\n",
    "            df_without_duplicates = df_without_duplicates.drop(df.index[index])\n",
    "\n",
    "        df = df_without_duplicates\n",
    "        count = 0\n",
    "        lastDuplicate = duplicates.iloc[0][self.groupBy]\n",
    "        columns = duplicates.columns.values\n",
    "        for index,row in duplicates.iterrows():\n",
    "            entry = duplicates.iloc[index]\n",
    "            name = entry[self.groupBy]\n",
    "            if(name == lastDuplicate):\n",
    "                count += 1\n",
    "            else:\n",
    "                df = df.append(self._getUniqueRow(duplicates,index-count,index),ignore_index=True)\n",
    "                lastDuplicate = name\n",
    "                count = 1\n",
    "        \n",
    "            if(len(duplicates) - 1 == index):\n",
    "                df = df.append(self._getUniqueRow(duplicates,index-count+1,index + 1),ignore_index=True)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadáme nežiaduce znaky ako parametre, a následne preiterujeme všetky údaje, a pokiaľ narazíme na daný nežiaduci znak, tak mu priradíme NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToNaNTransformer(TransformerMixin):\n",
    "    def __init__(self,signs):\n",
    "        self.signs = signs\n",
    "    \n",
    "    def _checkSign(self,x):\n",
    "        for sign in self.signs:\n",
    "            if sign == str(x).strip(\" \"):\n",
    "                return True\n",
    "        return False\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].map(lambda x: np.nan if self._checkSign(x) else x)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokiaľ máme stĺpec, ktorý obsahuje objekty, tak ho rozložíme na viacero stĺpcov. Pôvodný stĺpec nevymazávame, pretože ho možno ešte budeme potrebovať."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectValuesTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.cols = columns\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for index, row in df.iterrows():\n",
    "            for column in self.cols:\n",
    "                if(str(row[column]) != 'nan'):\n",
    "                    newRow = eval(str(row[column]))\n",
    "                    for key, value in newRow.items():\n",
    "                        df.loc[index,key] = value\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na zvolených stĺpcoch vyráta priemernú hodnotu, a doplní do NaN hodnôt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.col_means = {}\n",
    "        \n",
    "    def fit(self,df, y=None):\n",
    "        \n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: float(x))\n",
    "            self.col_means[column] = math.floor(np.nanmean(df[column].tolist()))\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: self.col_means[column] if str(x).lower() == 'nan' else float(x))\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sformátovanie rôznych formátov dátumov na jednotný formát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatDateTransformer(TransformerMixin):\n",
    "    def __init__(self,column):\n",
    "        self.column = column\n",
    "    def _format_date(self,string):\n",
    "        for fmt in [\"%Y/%m/%d\", \"%Y%m%d\", \"%y-%m-%d\", \"%Y-%m-%d\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d %H %M %S\", \"%d/%m/%Y\"]:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(string, fmt).date()\n",
    "            except ValueError:\n",
    "                continue\n",
    "        raise ValueError(string)\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        df[self.column] = df[self.column].map(lambda x: self._format_date(x) if type(x) is str else x)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táto funkcia vyráta priemerný dátum pre NaN hodnotu, spomedzi všetkých dátumov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanDateTransformer(TransformerMixin):\n",
    "    def __init__(self,age_column,date_column):\n",
    "        self.age_column = age_column\n",
    "        self.date_column = date_column\n",
    "        self.mean_age = 0;\n",
    "        self.mean_date = 0;\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        self.mean_age = np.nanmean(df[self.age_column].tolist())\n",
    "        self.mean_date = datetime.datetime(math.floor(datetime.datetime.now().year - self.mean_age), datetime.datetime.now().month, datetime.datetime.now().day,\n",
    "                           datetime.datetime.now().hour, datetime.datetime.now().minute).date()\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        df[self.date_column] = df[self.date_column].map(lambda x: self.mean_date if str(x) == 'nan' else x)\n",
    "        i = 0\n",
    "        for date in df[self.date_column]:\n",
    "            if(date > datetime.datetime.now().date()):\n",
    "                modifiedDate = datetime.datetime(datetime.datetime.now().year-int(df[self.age_column][i]), date.month, date.day).date()\n",
    "                df[self.date_column][i] = modifiedDate \n",
    "            i += 1\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre daný stĺpec, ktorý ma obsahovať len T a F hodnoty (no obsahuje aj nežiaduce hodnoty ako False,FALSE,F.15) urobíme algoritmus, ktorý zjednotí všetky hodnoty len na prislúchajúce T a F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueFalseTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "    def _mapTrueFalse(self,x):\n",
    "        if(\"t\" in str(x).lower()):\n",
    "            return \"t\"\n",
    "        elif(\"f\" in str(x).lower()):\n",
    "            return \"f\"\n",
    "        else:\n",
    "            return np.nan\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: self._mapTrueFalse(x))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmus vyráta pre stĺpec medián, a doplní ho do NaN riadkov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedianTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.cols_median = {}\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: float(x))\n",
    "            self.cols_median[column] = np.nanmedian(df[column].tolist())\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: self.cols_median[column] if str(x).lower() == 'nan' else x)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táto funkcia doplní do NaN riadkov určitú hodnotu. Táto hodnota sa vyráta nasledovne: Zistíme pomer všetkých hodnôt, a náhodne sa na základe toho vyberie hodnota, ktorá sa vloží do NaN riadku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.cols_value_to_fill = {}\n",
    "    def fit(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            self.cols_value_to_fill[column] = pd.Series(np.random.choice(self._getUniqueValues(df[column]),p=self._getRatio(df[column]),size=len(df[column])))\n",
    "        return self\n",
    "    \n",
    "    def _getUniqueValues(self,arr):\n",
    "        return arr.value_counts(normalize=True, dropna=True).index\n",
    "\n",
    "    def _getRatio(self,arr):\n",
    "        return arr.value_counts(normalize=True, dropna=True).values\n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].fillna(self.cols_value_to_fill[column])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako parametrom je pole objektov, ktorý sa zkladá z: 1.stĺpec, 2. znak z ktorého chceme meniť, 3.znak na ktorý chceme meniť. Čiže v určitom stĺpci zmeníme jeden znak na druhý. Taktiež v tejto funkcií dáme všetky znaky na malé písmená."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplacerTransformer(TransformerMixin):\n",
    "    def __init__(self,replace_info_arr):\n",
    "        self.all_info = []\n",
    "        for replace_info in replace_info_arr:\n",
    "            self.all_info.append(replace_info)\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for info in self.all_info:\n",
    "            df[info[\"column\"]] = df[info[\"column\"]].map(lambda x: str(x).lower().replace(info[\"current\"],info[\"new\"]))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do NaN hodnôt sa dosadí hodnota. Táto hodnota je vyrátaná ako: Zoberieme S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnearestTransformer(TransformerMixin):\n",
    "    def __init__(self,columns,k=3):\n",
    "        self.columns = columns\n",
    "        self.k_num = k\n",
    "    \n",
    "    def _kNearest(self,df,column,k=3):\n",
    "        kNearest = []\n",
    "        i = 0\n",
    "        for item in df[column]:\n",
    "            if(str(item) == 'nan'):\n",
    "                kNearest = []\n",
    "                for index in range(2*k+1):\n",
    "                    if(i+k-index < len(df) and i+k-index > -1 and i+k-index != i and str(df[column][i+k-index]) != 'nan'):\n",
    "                        kNearest.append(df[column][i+k-index])\n",
    "                nearestAvg = reduce(lambda x, y: x + y, kNearest) / len(kNearest)\n",
    "                df[column][i] = math.floor(nearestAvg)\n",
    "            i += 1\n",
    "        return df\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "               df = self._kNearest(df,column,self.k_num)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age je špecifický stĺpec, pre ktorý odstraňujeme vychýlené hodnoty. Keďže veku prislúcha aj dátum, tak pri hodnotách, ktoré zmeníme pri Age stĺpci, tak ich zmeníme aj pri dátume (tak, aby dátum narodenia sedel s vekom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutleirsRemovalForAgeAndDateTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self,age_column,date_column,value):\n",
    "        self.age_column = age_column\n",
    "        self.date_column = date_column\n",
    "        self.value = value\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for index,row in df.iterrows():\n",
    "            if(df[self.age_column][index] > self.value):\n",
    "                df[self.age_column][index] = self.value\n",
    "                df[self.date_column] = datetime.datetime(math.floor(datetime.datetime.now().year - self.value), df[self.date_column][index].month, df[self.date_column][index].day).date()\n",
    "                \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na všetkych stĺpcoch, o ktorých predpokladáme, že majú byť číselné, vykonáme túto funkciu, ktorá z nich urobí floaty (aj keď predtým boli stringy, alebo objekty). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatToFloatTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: float(x))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nahradenie vychýlené hodnoty z float stĺpca. Výchýlená hodnota je hodnota menšia ako 5 percentil alebo väčšia ako 95 percentil. Pokiaľ je číslo menšie ako 5 percentil, nahradíme ju číslom, ktoré je rovné 5 percentilu, a ak je väčšie ako 95 percentil, nahradíme ju číslom, ktoré reprezentuje 95 percentil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutleirsRemoval(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.outlayer_95 = {}\n",
    "        self.outlayer_5 = {}\n",
    "    def fit(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            self.outlayer_95[column] = np.nanpercentile(df[column],95)\n",
    "            self.outlayer_5[column] = np.nanpercentile(df[column],5)\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for index,row in df.iterrows():\n",
    "            for column in self.columns:\n",
    "                if df[column][index] > self.outlayer_95[column]:\n",
    "                    df[column][index] = self.outlayer_95[column]\n",
    "                elif df[column][index] < self.outlayer_5[column]:\n",
    "                    df[column][index] = self.outlayer_5[column]\n",
    "        return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false_columns = [\"sick\",\"T3 measured\",\"query hypothyroid\", \"query hyperthyroid\",\"FTI measured\",\"lithium\",\"TT4 measured\", \"pregnant\",\n",
    "                     \"thyroid surgery\",\"TBG measured\",\"TSH measured\",\"query on thyroxine\",\"I131 treatment\",\"on thyroxine\",\"psych\", \"T4U measured\", \"tumor\",\n",
    "                    \"goitre\",\"hypopituitary\",\"on antithyroid medication\"]\n",
    "\n",
    "categorical_columns = [\"sick\",\"query hypothyroid\", \"query hyperthyroid\",\"FTI measured\",\"lithium\",\"TT4 measured\", \"pregnant\",\n",
    "                     \"thyroid surgery\",\"TSH measured\",\"query on thyroxine\",\"I131 treatment\",\"on thyroxine\",\"psych\", \"tumor\",\n",
    "                     \"goitre\",\"hypopituitary\",\"on antithyroid medication\",\"sex\",\"workclass\",\"native-country\",\"occupation\",\"T3 measured\",\"T4U measured\"]\n",
    "\n",
    "replace_info = [\n",
    "    {\n",
    "        \"column\":\"education\",\n",
    "        \"current\":\"_\",\n",
    "        \"new\":\"-\"\n",
    "    },\n",
    "    {\n",
    "        \"column\":\"class\",\n",
    "        \"current\": \".|\",\n",
    "        \"new\":\"|\"\n",
    "    }\n",
    "]\n",
    "\n",
    "pip_merge = Pipeline([\n",
    "    ('merge',MergeTransformer(personal_data,other_data,[\"name\",\"address\"]))\n",
    "])\n",
    "pip = Pipeline([\n",
    "    ('objectvalues',ObjectValuesTransformer([\"medical_info\"])),\n",
    "    ('deduplicate',DeduplicationTransformer([\"name\",\"address\"],\"name\")),\n",
    "    ('nan',ToNaNTransformer([\"?\",\"nan\",\"?.4\"])),\n",
    "    ('format-date',FormatDateTransformer(\"date_of_birth\")),\n",
    "    ('format-to-floats',FormatToFloatTransformer([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('date-outlayers',OutleirsRemovalForAgeAndDateTransformer(\"age\",\"date_of_birth\",110)),\n",
    "    ('outlayers',OutleirsRemoval([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('mean',MeanTransformer([\"age\",\"T4U\",\"capital-loss\",\"TSH\",\"FTI\",\"fnlwgt\",\"hours-per-week\"])),\n",
    "    ('median',MedianTransformer([\"T3\",\"education-num\"])),\n",
    "    ('knearest',KnearestTransformer([\"TT4\"])),\n",
    "    ('date',MeanDateTransformer(\"age\",\"date_of_birth\")),\n",
    "    ('true-false-mapping',TrueFalseTransformer(true_false_columns)),\n",
    "    ('categorical',CategoricalTransformer(categorical_columns)),\n",
    "    ('replacer',ReplacerTransformer(replace_info))\n",
    "])\n",
    "merged_before_transform = pd.DataFrame()\n",
    "model = pip_merge.fit(merged_before_transform)\n",
    "merged_before_transform = model.transform(merged_before_transform)\n",
    "model = pip.fit(merged_before_transform)\n",
    "merged = model.transform(merged_before_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mergnutie validneho datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data_valid = pd.read_csv('./data/personal_valid.csv')\n",
    "personal_data_valid = personal_data_valid.drop(['Unnamed: 0'],axis=1)\n",
    "other_data_valid = pd.read_csv('./data/other_valid.csv')\n",
    "other_data_valid = other_data_valid.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "pip_merge_valid = Pipeline([\n",
    "     ('merge',MergeTransformer(personal_data_valid,other_data_valid,[\"name\",\"address\"]))\n",
    "]) \n",
    "merged_valid_before_transform = pd.DataFrame()\n",
    "model_valid = pip_merge_valid.fit(merged_valid_before_transform)\n",
    "merged_valid_before_transform = model_valid.transform(merged_valid_before_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spustenie predspracovanie z druheho zadania na vyssie mergnuty dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_valid = model.transform(merged_valid_before_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline pre druhu variantu doplnania v druho odovzdani sme vacsinu float stlpcov doplnali priemerom preto sa pokusime v tejto pipeline doplnat viac stlpcov medianom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip_merge2 = Pipeline([\n",
    "    ('merge',MergeTransformer(personal_data,other_data,[\"name\",\"address\"]))\n",
    "])\n",
    "pip2 = Pipeline([\n",
    "    ('objectvalues',ObjectValuesTransformer([\"medical_info\"])),\n",
    "    ('deduplicate',DeduplicationTransformer([\"name\",\"address\"],\"name\")),\n",
    "    ('nan',ToNaNTransformer([\"?\",\"nan\",\"?.4\"])),\n",
    "    ('format-date',FormatDateTransformer(\"date_of_birth\")),\n",
    "    ('format-to-floats',FormatToFloatTransformer([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('date-outlayers',OutleirsRemovalForAgeAndDateTransformer(\"age\",\"date_of_birth\",110)),\n",
    "    ('outlayers',OutleirsRemoval([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('median',MedianTransformer([\"age\",\"T4U\",\"capital-loss\",\"TSH\",\"FTI\",\"fnlwgt\",\"hours-per-week\"])),\n",
    "    ('mean',MeanTransformer([\"T3\",\"education-num\"])),\n",
    "    ('knearest',KnearestTransformer([\"TT4\"])),\n",
    "    ('date',MeanDateTransformer(\"age\",\"date_of_birth\")),\n",
    "    ('true-false-mapping',TrueFalseTransformer(true_false_columns)),\n",
    "    ('categorical',CategoricalTransformer(categorical_columns)),\n",
    "    ('replacer',ReplacerTransformer(replace_info))\n",
    "])\n",
    "merged2_before_transform = pd.DataFrame()\n",
    "model2 = pip_merge2.fit(merged2_before_transform)\n",
    "merged2_before_transform = model2.transform(merged2_before_transform)\n",
    "model2 = pip2.fit(merged2_before_transform)\n",
    "merged2 = model2.transform(merged2_before_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBG stlpec dame vsetko na null kedze tam mame len NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"TBG\"] = 0\n",
    "merged2[\"TBG\"] = 0\n",
    "merged_valid[\"TBG\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropneme medical info pre vsetky datasety kedze sme ho v predspracovani uz rozdelili je nam nepotrebný"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(['medical_info'],axis=1)\n",
    "merged2 = merged2.drop([\"medical_info\"],axis=1)\n",
    "merged_valid = merged_valid.drop(['medical_info'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitCols(df,column,splitter, columns):\n",
    "    split = pd.DataFrame(df[column].str.split(\"|\",2).tolist(),columns = columns)\n",
    "    df = df.drop([column],axis=1)\n",
    "    return pd.concat([df,split],axis=1,sort=False)\n",
    "\n",
    "def encoding(df,columns):\n",
    "    dummies = pd.concat([pd.get_dummies(df[column],prefix=column) for column in columns],axis=1,sort=False)\n",
    "    df = df.drop(columns,axis=1)\n",
    "    return pd.concat([df, dummies], axis=1,sort=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodneme jednotlive kategoricke stlpce a nasledne samostatne encodneme stlpec class kedze chceme len jeden stlpec kde negative je 0 increased 1 a decreased 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged = splitCols(merged,\"class\",'|',[\"class\",\"class_value\"])\n",
    "merged = encoding(merged,categorical_columns)\n",
    "\n",
    "merged2 = splitCols(merged2,\"class\",'|',[\"class\",\"class_value\"])\n",
    "merged2 = encoding(merged2,categorical_columns)\n",
    "\n",
    "merged_valid = splitCols(merged_valid,\"class\",'|',[\"class\",\"class_value\"])\n",
    "merged_valid = encoding(merged_valid,categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classEncoder(x):\n",
    "    if(x == 'negative'):\n",
    "        return 0\n",
    "    elif (x =='increased binding protein'):\n",
    "        return 1\n",
    "    elif (x == 'decreased binding protein'):\n",
    "        return 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapClassColumn(dfs):\n",
    "    newDfs = list()\n",
    "    for df in dfs:\n",
    "        df[\"class\"] = df[\"class\"].map(lambda x: classEncoder(x))\n",
    "        newDfs.append(df)\n",
    "    return newDfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged, merged2, merged_valid = mapClassColumn([merged,merged2,merged_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vymazeme vsetky object columny kedze su uz zakodovane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeObjectColumns(dfs):\n",
    "    newDfs = list()\n",
    "    for df in dfs:\n",
    "        for column in df.columns:\n",
    "            if(df[column].dtype == 'object'):\n",
    "                df = df.drop([column],axis=1)\n",
    "        newDfs.append(df)\n",
    "    return newDfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged,merged2,merged_valid = removeObjectColumns([merged,merged2,merged_valid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumn(df_valid, df_train):\n",
    "    for x in np.array(list(set(df_train.columns).difference(set(df_valid.columns)))):\n",
    "        df_valid[x] = 0\n",
    "    return df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_valid = addColumn(merged_valid, merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-0332d0ad6c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m GridSearchTree = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, scoring=\"f1_macro\", cv=10, refit=\"f1_macro\", \n\u001b[0;32m      3\u001b[0m                                   return_train_score=True)\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mGridSearchTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_train' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\"max_depth\":np.arange(5,15),\"min_samples_leaf\" : np.arange(1, 3),'max_leaf_nodes': np.arange(2, 32)}\n",
    "GridSearchTree = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, scoring=\"f1_macro\", cv=10, refit=\"f1_macro\", \n",
    "                                  return_train_score=True)\n",
    "GridSearchTree.fit(merged_train, merged_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth , max_leaf_nodes, min_samples_leaf = GridSearchTree.best_params_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(GridSearchTree.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viac stlpcov doplenych o priemer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = tree.DecisionTreeClassifier(max_depth=max_depth, max_leaf_nodes=max_leaf_nodes, min_samples_leaf=min_samples_leaf)\n",
    "cols = merged.columns\n",
    "cols = list(cols)\n",
    "cols.remove('class')\n",
    "X = merged[cols]\n",
    "y = merged['class']\n",
    "cls.fit(X,y)\n",
    "\n",
    "test = merged_valid[cols]\n",
    "prediction = cls.predict(test)\n",
    "\n",
    "classification_report(merged_valid[\"class\"], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viac stlpcov doplnenych o median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = tree.DecisionTreeClassifier(max_depth=max_depth, max_leaf_nodes=max_leaf_nodes, min_samples_leaf=min_samples_leaf)\n",
    "cols = merged2.columns\n",
    "cols = list(cols)\n",
    "cols.remove('class')\n",
    "X = merged2[cols]\n",
    "y = merged2['class']\n",
    "cls.fit(X,y)\n",
    "\n",
    "test = merged_valid[cols]\n",
    "prediction = cls.predict(test)\n",
    "\n",
    "print(classification_report(merged_valid[\"class\"], prediction)) \n",
    "print(\"Správnosť\", accuracy_score(merged_valid[\"class\"], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vlastny klasifikator. Ten kto ma hodnotu t4u viac ako 95 percentil ma decreased protein binding a ten kto ma mensiu ako 25 ma increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_95_percentile = np.percentile(merged_valid[\"T4U\"],95)\n",
    "columns_5_percentile = np.percentile(merged_valid[\"T4U\"],5)\n",
    "\n",
    "def fillValue(x):\n",
    "    if(x > columns_75_percentile):\n",
    "        return 2\n",
    "    elif (x < columns_25_percentile):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "predicted_column = merged_valid[\"T4U\"].map(lambda x: fillValue(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(merged_valid[\"class\"], predicted_column)) \n",
    "print(\"Správnosť\", accuracy_score(merged_valid[\"class\"], predicted_column))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
