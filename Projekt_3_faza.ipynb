{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import randint\n",
    "import math\n",
    "from datetime import date\n",
    "import datetime\n",
    "from functools import reduce\n",
    "import warnings\n",
    "import random\n",
    "import re\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data = pd.read_csv('./data/personal_train.csv')\n",
    "personal_data = personal_data.drop(['Unnamed: 0'],axis=1)\n",
    "other_data = pd.read_csv('./data/other_train.csv')\n",
    "other_data = other_data.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zlúčenie dvoch datasetov do jedného, na základe stĺpcov, alebo stĺpca (v parametroch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MergeTransformer(TransformerMixin):\n",
    "    def __init__(self,df1,df2,cols):\n",
    "        self.df1 = df1\n",
    "        self.df2 = df2\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        df = pd.merge(self.df1,self.df2,on=self.cols)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprv sa uložia všetky duplikáty z DF, v pôvodnom sa vymažú, a následne sa vytvorí 1 unikátny záznam z množiny duplikátov, ktorý sa uloží na pôvodný dataset. Ak má stĺpec: spojité hodnoty, tak sa vyráta priemer. Ak má diskrétne, tak sa priradí náhodne, ak má samé NaN alebo ?, tak NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeduplicationTransformer(TransformerMixin):\n",
    "    def __init__(self,cols,groupBy):\n",
    "        self.cols = cols\n",
    "        self.groupBy = groupBy\n",
    "    \n",
    "    def _checkNaN(self,arr):\n",
    "        for item in arr:\n",
    "            if((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item)):\n",
    "                return False\n",
    "        return True\n",
    "    def _checkQuestionMark(self,arr):\n",
    "        for item in arr:\n",
    "            if(item is not '?'):\n",
    "                return False\n",
    "        return True\n",
    "    def _nanOrQuestionMark(self,arr):\n",
    "        for item in arr:\n",
    "            if(item is not '?' and ((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item))):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _filter_nan_question_mark(self,arr):\n",
    "        result = []\n",
    "        for item in arr:\n",
    "            if(item is not '?' and ((type(item) is not np.float64 and type(item) is not float) or not np.isnan(item))):\n",
    "                result.append(item)\n",
    "        return result \n",
    "    \n",
    "    def _getUniqueRow(self,duplicates,startIndex,endIndex):\n",
    "        row_dict = {}\n",
    "\n",
    "        for column in duplicates.columns: \n",
    "            temp = []\n",
    "            for index in range(startIndex,endIndex):\n",
    "                temp.append(duplicates.iloc[index][column])\n",
    "         \n",
    "            if(self._checkNaN(temp)):\n",
    "                row_dict[column] = np.nan\n",
    "            elif(self._checkQuestionMark(temp)):\n",
    "                row_dict[column] = np.nan\n",
    "            elif(self._nanOrQuestionMark(temp)):\n",
    "                row_dict[column] = np.nan\n",
    "            else:\n",
    "                temp = self._filter_nan_question_mark(temp)\n",
    "                if(np.array(temp).dtype == 'float64'):\n",
    "                    row_dict[column] = np.mean(temp)\n",
    "                else:\n",
    "                    value = randint(0,len(temp)-1)\n",
    "                    row_dict[column] = temp[value]\n",
    "        return row_dict\n",
    "\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        duplicated = df.duplicated(subset=self.cols,keep=False)\n",
    "        duplicates = pd.DataFrame(columns=df.columns)\n",
    "        indexes_to_drop = []\n",
    "        df_without_duplicates = pd.DataFrame(columns=df.columns)\n",
    "        for index, row in df.iterrows():\n",
    "            if(duplicated[index]):\n",
    "                duplicates = duplicates.append(df.iloc[index],ignore_index=True)\n",
    "                indexes_to_drop.append(index)\n",
    "\n",
    "        duplicates.sort_values(self.cols)\n",
    "        df_without_duplicates = df\n",
    "        for index in indexes_to_drop:\n",
    "            df_without_duplicates = df_without_duplicates.drop(df.index[index])\n",
    "\n",
    "        df = df_without_duplicates\n",
    "        count = 0\n",
    "        lastDuplicate = duplicates.iloc[0][self.groupBy]\n",
    "        columns = duplicates.columns.values\n",
    "        for index,row in duplicates.iterrows():\n",
    "            entry = duplicates.iloc[index]\n",
    "            name = entry[self.groupBy]\n",
    "            if(name == lastDuplicate):\n",
    "                count += 1\n",
    "            else:\n",
    "                df = df.append(self._getUniqueRow(duplicates,index-count,index),ignore_index=True)\n",
    "                lastDuplicate = name\n",
    "                count = 1\n",
    "        \n",
    "            if(len(duplicates) - 1 == index):\n",
    "                df = df.append(self._getUniqueRow(duplicates,index-count+1,index + 1),ignore_index=True)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadáme nežiaduce znaky ako parametre, a následne preiterujeme všetky údaje, a pokiaľ narazíme na daný nežiaduci znak, tak mu priradíme NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToNaNTransformer(TransformerMixin):\n",
    "    def __init__(self,signs):\n",
    "        self.signs = signs\n",
    "    \n",
    "    def _checkSign(self,x):\n",
    "        for sign in self.signs:\n",
    "            if sign == str(x).strip(\" \"):\n",
    "                return True\n",
    "        return False\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].map(lambda x: np.nan if self._checkSign(x) else x)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokiaľ máme stĺpec, ktorý obsahuje objekty, tak ho rozložíme na viacero stĺpcov. Pôvodný stĺpec nevymazávame, pretože ho možno ešte budeme potrebovať."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectValuesTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.cols = columns\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for index, row in df.iterrows():\n",
    "            for column in self.cols:\n",
    "                if(str(row[column]) != 'nan'):\n",
    "                    newRow = eval(str(row[column]))\n",
    "                    for key, value in newRow.items():\n",
    "                        df.loc[index,key] = value\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na zvolených stĺpcoch vyráta priemernú hodnotu, a doplní do NaN hodnôt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.col_means = {}\n",
    "        \n",
    "    def fit(self,df, y=None):\n",
    "        \n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: float(x))\n",
    "            self.col_means[column] = math.floor(np.nanmean(df[column].tolist()))\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: self.col_means[column] if str(x).lower() == 'nan' else float(x))\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sformátovanie rôznych formátov dátumov na jednotný formát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatDateTransformer(TransformerMixin):\n",
    "    def __init__(self,column):\n",
    "        self.column = column\n",
    "    def _format_date(self,string):\n",
    "        for fmt in [\"%Y/%m/%d\", \"%Y%m%d\", \"%y-%m-%d\", \"%Y-%m-%d\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d %H %M %S\", \"%d/%m/%Y\"]:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(string, fmt).date()\n",
    "            except ValueError:\n",
    "                continue\n",
    "        raise ValueError(string)\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        df[self.column] = df[self.column].map(lambda x: self._format_date(x) if type(x) is str else x)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táto funkcia vyráta priemerný dátum pre NaN hodnotu, spomedzi všetkých dátumov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanDateTransformer(TransformerMixin):\n",
    "    def __init__(self,age_column,date_column):\n",
    "        self.age_column = age_column\n",
    "        self.date_column = date_column\n",
    "        self.mean_age = 0;\n",
    "        self.mean_date = 0;\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        self.mean_age = np.nanmean(df[self.age_column].tolist())\n",
    "        self.mean_date = datetime.datetime(math.floor(datetime.datetime.now().year - self.mean_age), datetime.datetime.now().month, datetime.datetime.now().day,\n",
    "                           datetime.datetime.now().hour, datetime.datetime.now().minute).date()\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        df[self.date_column] = df[self.date_column].map(lambda x: self.mean_date if str(x) == 'nan' else x)\n",
    "        i = 0\n",
    "        for date in df[self.date_column]:\n",
    "            if(date > datetime.datetime.now().date()):\n",
    "                modifiedDate = datetime.datetime(datetime.datetime.now().year-int(df[self.age_column][i]), date.month, date.day).date()\n",
    "                df[self.date_column][i] = modifiedDate \n",
    "            i += 1\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre daný stĺpec, ktorý ma obsahovať len T a F hodnoty (no obsahuje aj nežiaduce hodnoty ako False,FALSE,F.15) urobíme algoritmus, ktorý zjednotí všetky hodnoty len na prislúchajúce T a F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueFalseTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "    def _mapTrueFalse(self,x):\n",
    "        if(\"t\" in str(x).lower()):\n",
    "            return \"t\"\n",
    "        elif(\"f\" in str(x).lower()):\n",
    "            return \"f\"\n",
    "        else:\n",
    "            return np.nan\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: self._mapTrueFalse(x))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmus vyráta pre stĺpec medián, a doplní ho do NaN riadkov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedianTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.cols_median = {}\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: float(x))\n",
    "            self.cols_median[column] = np.nanmedian(df[column].tolist())\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: self.cols_median[column] if str(x).lower() == 'nan' else x)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táto funkcia doplní do NaN riadkov určitú hodnotu. Táto hodnota sa vyráta nasledovne: Zistíme pomer všetkých hodnôt, a náhodne sa na základe toho vyberie hodnota, ktorá sa vloží do NaN riadku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.cols_value_to_fill = {}\n",
    "    def fit(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            self.cols_value_to_fill[column] = pd.Series(np.random.choice(self._getUniqueValues(df[column]),p=self._getRatio(df[column]),size=len(df[column])))\n",
    "        return self\n",
    "    \n",
    "    def _getUniqueValues(self,arr):\n",
    "        return arr.value_counts(normalize=True, dropna=True).index\n",
    "\n",
    "    def _getRatio(self,arr):\n",
    "        return arr.value_counts(normalize=True, dropna=True).values\n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].fillna(self.cols_value_to_fill[column])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako parametrom je pole objektov, ktorý sa zkladá z: 1.stĺpec, 2. znak z ktorého chceme meniť, 3.znak na ktorý chceme meniť. Čiže v určitom stĺpci zmeníme jeden znak na druhý. Taktiež v tejto funkcií dáme všetky znaky na malé písmená."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplacerTransformer(TransformerMixin):\n",
    "    def __init__(self,replace_info_arr):\n",
    "        self.all_info = []\n",
    "        for replace_info in replace_info_arr:\n",
    "            self.all_info.append(replace_info)\n",
    "        \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for info in self.all_info:\n",
    "            df[info[\"column\"]] = df[info[\"column\"]].map(lambda x: str(x).lower().replace(info[\"current\"],info[\"new\"]))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do NaN hodnôt sa dosadí hodnota. Táto hodnota je vyrátaná ako: Zoberieme S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnearestTransformer(TransformerMixin):\n",
    "    def __init__(self,columns,k=3):\n",
    "        self.columns = columns\n",
    "        self.k_num = k\n",
    "    \n",
    "    def _kNearest(self,df,column,k=3):\n",
    "        kNearest = []\n",
    "        i = 0\n",
    "        for item in df[column]:\n",
    "            if(str(item) == 'nan'):\n",
    "                kNearest = []\n",
    "                for index in range(2*k+1):\n",
    "                    if(i+k-index < len(df) and i+k-index > -1 and i+k-index != i and str(df[column][i+k-index]) != 'nan'):\n",
    "                        kNearest.append(df[column][i+k-index])\n",
    "                nearestAvg = reduce(lambda x, y: x + y, kNearest) / len(kNearest)\n",
    "                df[column][i] = math.floor(nearestAvg)\n",
    "            i += 1\n",
    "        return df\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "               df = self._kNearest(df,column,self.k_num)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age je špecifický stĺpec, pre ktorý odstraňujeme vychýlené hodnoty. Keďže veku prislúcha aj dátum, tak pri hodnotách, ktoré zmeníme pri Age stĺpci, tak ich zmeníme aj pri dátume (tak, aby dátum narodenia sedel s vekom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutleirsRemovalForAgeAndDateTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self,age_column,date_column,value):\n",
    "        self.age_column = age_column\n",
    "        self.date_column = date_column\n",
    "        self.value = value\n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for index,row in df.iterrows():\n",
    "            if(df[self.age_column][index] > self.value):\n",
    "                df[self.age_column][index] = self.value\n",
    "                df[self.date_column] = datetime.datetime(math.floor(datetime.datetime.now().year - self.value), df[self.date_column][index].month, df[self.date_column][index].day).date()\n",
    "                \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na všetkych stĺpcoch, o ktorých predpokladáme, že majú byť číselné, vykonáme túto funkciu, ktorá z nich urobí floaty (aj keď predtým boli stringy, alebo objekty). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatToFloatTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            df[column] = df[column].map(lambda x: float(x))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nahradenie vychýlené hodnoty z float stĺpca. Výchýlená hodnota je hodnota menšia ako 5 percentil alebo väčšia ako 95 percentil. Pokiaľ je číslo menšie ako 5 percentil, nahradíme ju číslom, ktoré je rovné 5 percentilu, a ak je väčšie ako 95 percentil, nahradíme ju číslom, ktoré reprezentuje 95 percentil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutleirsRemoval(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "        self.outlayer_95 = {}\n",
    "        self.outlayer_5 = {}\n",
    "    def fit(self,df,y=None):\n",
    "        for column in self.columns:\n",
    "            self.outlayer_95[column] = np.nanpercentile(df[column],95)\n",
    "            self.outlayer_5[column] = np.nanpercentile(df[column],5)\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        for index,row in df.iterrows():\n",
    "            for column in self.columns:\n",
    "                if df[column][index] > self.outlayer_95[column]:\n",
    "                    df[column][index] = self.outlayer_95[column]\n",
    "                elif df[column][index] < self.outlayer_5[column]:\n",
    "                    df[column][index] = self.outlayer_5[column]\n",
    "        return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false_columns = [\"sick\",\"T3 measured\",\"query hypothyroid\", \"query hyperthyroid\",\"FTI measured\",\"lithium\",\"TT4 measured\", \"pregnant\",\n",
    "                     \"thyroid surgery\",\"TBG measured\",\"TSH measured\",\"query on thyroxine\",\"I131 treatment\",\"on thyroxine\",\"psych\", \"T4U measured\", \"tumor\",\n",
    "                    \"goitre\",\"hypopituitary\",\"on antithyroid medication\"]\n",
    "\n",
    "categorical_columns = [\"sick\",\"query hypothyroid\", \"query hyperthyroid\",\"FTI measured\",\"lithium\",\"TT4 measured\", \"pregnant\",\n",
    "                     \"thyroid surgery\",\"TSH measured\",\"query on thyroxine\",\"I131 treatment\",\"on thyroxine\",\"psych\", \"tumor\",\n",
    "                     \"goitre\",\"hypopituitary\",\"on antithyroid medication\",\"sex\",\"workclass\",\"native-country\",\"occupation\",\"T3 measured\",\"T4U measured\"]\n",
    "\n",
    "replace_info = [\n",
    "    {\n",
    "        \"column\":\"education\",\n",
    "        \"current\":\"_\",\n",
    "        \"new\":\"-\"\n",
    "    },\n",
    "    {\n",
    "        \"column\":\"class\",\n",
    "        \"current\": \".|\",\n",
    "        \"new\":\"|\"\n",
    "    }\n",
    "]\n",
    "\n",
    "pip_merge = Pipeline([\n",
    "    ('merge',MergeTransformer(personal_data,other_data,[\"name\",\"address\"]))\n",
    "])\n",
    "pip = Pipeline([\n",
    "    ('objectvalues',ObjectValuesTransformer([\"medical_info\"])),\n",
    "    ('deduplicate',DeduplicationTransformer([\"name\",\"address\"],\"name\")),\n",
    "    ('nan',ToNaNTransformer([\"?\",\"nan\",\"?.4\"])),\n",
    "    ('format-date',FormatDateTransformer(\"date_of_birth\")),\n",
    "    ('format-to-floats',FormatToFloatTransformer([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('date-outlayers',OutleirsRemovalForAgeAndDateTransformer(\"age\",\"date_of_birth\",110)),\n",
    "    ('outlayers',OutleirsRemoval([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('mean',MeanTransformer([\"age\",\"T4U\",\"capital-loss\",\"TSH\",\"FTI\",\"fnlwgt\",\"hours-per-week\"])),\n",
    "    ('median',MedianTransformer([\"T3\",\"education-num\"])),\n",
    "    ('knearest',KnearestTransformer([\"TT4\"])),\n",
    "    ('date',MeanDateTransformer(\"age\",\"date_of_birth\")),\n",
    "    ('true-false-mapping',TrueFalseTransformer(true_false_columns)),\n",
    "    ('categorical',CategoricalTransformer(categorical_columns)),\n",
    "    ('replacer',ReplacerTransformer(replace_info))\n",
    "])\n",
    "merged_before_transform = pd.DataFrame()\n",
    "model = pip_merge.fit(merged_before_transform)\n",
    "merged_before_transform = model.transform(merged_before_transform)\n",
    "model = pip.fit(merged_before_transform)\n",
    "merged = model.transform(merged_before_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data_valid = pd.read_csv('./data/personal_valid.csv')\n",
    "personal_data_valid = personal_data_valid.drop(['Unnamed: 0'],axis=1)\n",
    "other_data_valid = pd.read_csv('./data/other_valid.csv')\n",
    "other_data_valid = other_data_valid.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "pip_merge_valid = Pipeline([\n",
    "     ('merge',MergeTransformer(personal_data_valid,other_data_valid,[\"name\",\"address\"]))\n",
    "]) \n",
    "merged_valid_before_transform = pd.DataFrame()\n",
    "model_valid = pip_merge_valid.fit(merged_valid_before_transform)\n",
    "merged_valid_before_transform = model_valid.transform(merged_valid_before_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_valid = model.transform(merged_valid_before_transform)\n",
    "merged_valid = merged_valid.drop(['medical_info'],axis=1)\n",
    "merged_valid[\"TBG\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972 entries, 0 to 971\n",
      "Data columns (total 45 columns):\n",
      "name                         972 non-null object\n",
      "address                      972 non-null object\n",
      "age                          972 non-null float64\n",
      "sex                          972 non-null object\n",
      "date_of_birth                972 non-null object\n",
      "query hyperthyroid           972 non-null object\n",
      "FTI measured                 972 non-null object\n",
      "education                    972 non-null object\n",
      "lithium                      972 non-null object\n",
      "TT4                          972 non-null float64\n",
      "T4U                          972 non-null float64\n",
      "capital-loss                 972 non-null float64\n",
      "capital-gain                 972 non-null float64\n",
      "tumor                        972 non-null object\n",
      "TSH                          972 non-null float64\n",
      "T3                           972 non-null float64\n",
      "fnlwgt                       972 non-null float64\n",
      "hours-per-week               972 non-null float64\n",
      "relationship                 972 non-null object\n",
      "sick                         972 non-null object\n",
      "workclass                    972 non-null object\n",
      "TT4 measured                 972 non-null object\n",
      "class                        972 non-null object\n",
      "marital-status               972 non-null object\n",
      "goitre                       972 non-null object\n",
      "native-country               972 non-null object\n",
      "hypopituitary                972 non-null object\n",
      "on antithyroid medication    972 non-null object\n",
      "referral source              972 non-null object\n",
      "education-num                972 non-null float64\n",
      "occupation                   972 non-null object\n",
      "TBG measured                 972 non-null object\n",
      "TBG                          972 non-null int64\n",
      "race                         972 non-null object\n",
      "FTI                          972 non-null float64\n",
      "query hypothyroid            972 non-null object\n",
      "T4U measured                 972 non-null object\n",
      "pregnant                     972 non-null object\n",
      "thyroid surgery              972 non-null object\n",
      "TSH measured                 972 non-null object\n",
      "query on thyroxine           972 non-null object\n",
      "I131 treatment               972 non-null object\n",
      "on thyroxine                 972 non-null object\n",
      "T3 measured                  972 non-null object\n",
      "psych                        972 non-null object\n",
      "dtypes: float64(11), int64(1), object(33)\n",
      "memory usage: 341.8+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip_merge2 = Pipeline([\n",
    "    ('merge',MergeTransformer(personal_data,other_data,[\"name\",\"address\"]))\n",
    "])\n",
    "pip2 = Pipeline([\n",
    "    ('objectvalues',ObjectValuesTransformer([\"medical_info\"])),\n",
    "    ('deduplicate',DeduplicationTransformer([\"name\",\"address\"],\"name\")),\n",
    "    ('nan',ToNaNTransformer([\"?\",\"nan\",\"?.4\"])),\n",
    "    ('format-date',FormatDateTransformer(\"date_of_birth\")),\n",
    "    ('format-to-floats',FormatToFloatTransformer([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('date-outlayers',OutleirsRemovalForAgeAndDateTransformer(\"age\",\"date_of_birth\",110)),\n",
    "    ('outlayers',OutleirsRemoval([\"age\",\"T4U\",\"capital-loss\",\"capital-gain\",\"TSH\",\"FTI\",\"T3\",\"education-num\",\"TT4\",\"hours-per-week\",\"fnlwgt\"])),\n",
    "    ('median',MedianTransformer([\"age\",\"T4U\",\"capital-loss\",\"TSH\",\"FTI\",\"fnlwgt\",\"hours-per-week\"])),\n",
    "    ('mean',MeanTransformer([\"T3\",\"education-num\"])),\n",
    "    ('knearest',KnearestTransformer([\"TT4\"])),\n",
    "    ('date',MeanDateTransformer(\"age\",\"date_of_birth\")),\n",
    "    ('true-false-mapping',TrueFalseTransformer(true_false_columns)),\n",
    "    ('categorical',CategoricalTransformer(categorical_columns)),\n",
    "    ('replacer',ReplacerTransformer(replace_info))\n",
    "])\n",
    "merged2_before_transform = pd.DataFrame()\n",
    "model2 = pip_merge2.fit(merged2_before_transform)\n",
    "merged2_before_transform = model2.transform(merged2_before_transform)\n",
    "model2 = pip2.fit(merged2_before_transform)\n",
    "merged2 = model2.transform(merged2_before_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"TBG\"] = 0\n",
    "merged2[\"TBG\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2 = merged2.drop([\"medical_info\"],axis=1)\n",
    "merged = merged.drop(['medical_info'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitCols(df,column,splitter, columns):\n",
    "    split = pd.DataFrame(df[column].str.split(\"|\",2).tolist(),columns = columns)\n",
    "    df = df.drop([column],axis=1)\n",
    "    return pd.concat([df,split],axis=1,sort=False)\n",
    "\n",
    "def encoding(df,columns):\n",
    "    dummies = pd.concat([pd.get_dummies(df[column],prefix=column) for column in columns],axis=1,sort=False)\n",
    "    df = df.drop(columns,axis=1)\n",
    "    return pd.concat([df, dummies], axis=1,sort=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = splitCols(merged,\"class\",'|',[\"class\",\"class_value\"])\n",
    "merged = encoding(merged,categorical_columns)\n",
    "\n",
    "merged2 = splitCols(merged2,\"class\",'|',[\"class\",\"class_value\"])\n",
    "merged2 = encoding(merged2,categorical_columns)\n",
    "\n",
    "merged_valid = splitCols(merged_valid,\"class\",'|',[\"class\",\"class_value\"])\n",
    "merged_valid = encoding(merged_valid,categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classEncoder(x):\n",
    "    if(x == 'negative'):\n",
    "        return 0\n",
    "    elif (x =='increased binding protein'):\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"class\"] = merged[\"class\"].map(lambda x: classEncoder(x))\n",
    "merged2[\"class\"] = merged2[\"class\"].map(lambda x: classEncoder(x))\n",
    "merged_valid[\"class\"] = merged_valid[\"class\"].map(lambda x: classEncoder(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeObjectColumns(df):\n",
    "    for column in df.columns:\n",
    "        if(df[column].dtype == 'object'):\n",
    "            df = df.drop([column],axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = removeObjectColumns(merged)\n",
    "merged2 = removeObjectColumns(merged2)\n",
    "merged_valid = removeObjectColumns(merged_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumn(df_valid, df_train):\n",
    "    for x in np.array(list(set(df_train.columns).difference(set(df_valid.columns)))):\n",
    "        df_valid[x] = 0\n",
    "    return df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_valid = addColumn(merged_valid, merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uloženie dát\n",
    "x_train = merged\n",
    "x_train = x_train.drop([\"class\"], axis=1)\n",
    "y_train = merged[\"class\"]\n",
    "x_test = merged_valid\n",
    "x_test = x_test.drop([\"class\"], axis=1)\n",
    "y_test = merged_valid[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierWithHyperparameters(trainX, cvX, trainY, cvY):\n",
    "    param_grid = {'max_depth': np.arange(10, 20), 'max_leaf_nodes': np.arange(5, 15), 'min_samples_leaf': np.arange(1, 11)}\n",
    "    GridSearchTree = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, scoring=\"f1_macro\", cv=10, refit=\"f1_macro\", \n",
    "                                  return_train_score=True)\n",
    "    GridSearchTree.fit(trainX, trainY)\n",
    "    tree_preds = GridSearchTree.predict_proba(cvX)[:, 1]\n",
    "    return GridSearchTree\n",
    "\n",
    "# Funkcia vyhodnotí úspešnosť pomocou klasifikačného reportu, ktorý obsahuje precision, recall a f1 a pomocou accuracy\n",
    "def metrics(arr1, arr2):\n",
    "    print(classification_report(arr1, arr2)) \n",
    "    print(\"Správnosť\", accuracy_score(arr1, arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hľadáme najlepšie parametre, spustíme 10-násobnú krížovú validáciu na rôzne hodnoty parametrov\n",
    "gridSearch = classifierWithHyperparameters(x_train, x_test, y_train, y_test)\n",
    "# Uložíme si najlepšie parametre, s ktorými budeme naďalej pracovať\n",
    "best_parameters = gridSearch.best_params_\n",
    "# Uložíme si všetky výsledky (je ich presne 1 000 pre každé spustenie)\n",
    "results = gridSearch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11, 'max_leaf_nodes': 7, 'min_samples_leaf': 7}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.608097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.608097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.608097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.608097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.608097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.604150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.604150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.604150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.604150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.604150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.603897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.603897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.603897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.603897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.603852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_max_depth param_max_leaf_nodes param_min_samples_leaf  \\\n",
       "626              16                    7                      7   \n",
       "526              15                    7                      7   \n",
       "426              14                    7                      7   \n",
       "126              11                    7                      7   \n",
       "326              13                    7                      7   \n",
       "736              17                    8                      7   \n",
       "36               10                    8                      7   \n",
       "536              15                    8                      7   \n",
       "436              14                    8                      7   \n",
       "336              13                    8                      7   \n",
       "137              11                    8                      8   \n",
       "937              19                    8                      8   \n",
       "637              16                    8                      8   \n",
       "837              18                    8                      8   \n",
       "227              12                    7                      8   \n",
       "\n",
       "     mean_test_score  \n",
       "626         0.608097  \n",
       "526         0.608097  \n",
       "426         0.608097  \n",
       "126         0.608097  \n",
       "326         0.608097  \n",
       "736         0.604150  \n",
       "36          0.604150  \n",
       "536         0.604150  \n",
       "436         0.604150  \n",
       "336         0.604150  \n",
       "137         0.603897  \n",
       "937         0.603897  \n",
       "637         0.603897  \n",
       "837         0.603897  \n",
       "227         0.603852  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDataFrame = pd.DataFrame(results)\n",
    "resultDataFrame.sort_values(\"mean_test_score\", ascending=False).head(15)[[\"param_max_depth\", \"param_max_leaf_nodes\", \"param_min_samples_leaf\", \"mean_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWithDecisionTree(x, y):\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=best_parameters[\"max_depth\"], \n",
    "                                             max_leaf_nodes=best_parameters[\"max_leaf_nodes\"], \n",
    "                                             min_samples_leaf=best_parameters[\"min_samples_leaf\"])\n",
    "    classifier = classifier.fit(x, y)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    metrics(y_test, y_pred)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vyhodnotenie úspešnosti strojového učenia pri doplnení chýbajúcich hodnôt mediánom\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       942\n",
      "           1       0.52      0.56      0.54        25\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       972\n",
      "   macro avg       0.50      0.52      0.51       972\n",
      "weighted avg       0.97      0.97      0.97       972\n",
      "\n",
      "Správnosť 0.970164609053498\n",
      "\n",
      "Vyhodnotenie úspešnosti strojového učenia pri doplnení chýbajúcich hodnôt priemerom\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       942\n",
      "           1       0.52      0.56      0.54        25\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       972\n",
      "   macro avg       0.50      0.52      0.51       972\n",
      "weighted avg       0.97      0.97      0.97       972\n",
      "\n",
      "Správnosť 0.970164609053498\n"
     ]
    }
   ],
   "source": [
    "print(\"Vyhodnotenie úspešnosti strojového učenia pri doplnení chýbajúcich hodnôt mediánom\\n\")\n",
    "classifier_median = predictWithDecisionTree(x_train, y_train)\n",
    "\n",
    "x_train_average = merged2\n",
    "x_train_average = x_train_average.drop([\"class\"], axis=1)\n",
    "y_train_average = merged2[\"class\"]\n",
    "\n",
    "print(\"\\nVyhodnotenie úspešnosti strojového učenia pri doplnení chýbajúcich hodnôt priemerom\\n\")\n",
    "classifier_average = predictWithDecisionTree(x_train_average, y_train_average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
